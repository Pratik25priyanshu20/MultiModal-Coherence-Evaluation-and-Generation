#!/usr/bin/env python3
"""
RQ1 Hybrid: SDXL-generated images + CLAP-retrieved audio.

Reuses SDXL images already generated by `run_rq1.py --generative`,
pairs them with CLAP-retrieved audio from the existing index.
This isolates the AudioLDM 2 distribution gap identified in the
fully generative experiment.

Design: 30 prompts × 1 seed × 3 conditions = 90 runs
  - baseline: SDXL image (matched) + retrieved audio (matched)
  - wrong_image: SDXL image (mismatched domain) + retrieved audio (matched)
  - wrong_audio: SDXL image (matched) + retrieved audio (mismatched domain)

Usage:
    python scripts/run_rq1_hybrid.py
    python scripts/run_rq1_hybrid.py --gen-results runs/rq1_gen/rq1_gen_results.json
"""

from __future__ import annotations

import argparse
import json
import sys
import time
from pathlib import Path
from typing import Any, Dict, List

import numpy as np

sys.path.insert(0, str(Path(__file__).resolve().parent.parent))


def main():
    parser = argparse.ArgumentParser(description="RQ1 Hybrid: SDXL images + CLAP retrieval audio")
    parser.add_argument("--gen-results", default="runs/rq1_gen/rq1_gen_results.json",
                        help="Path to generative RQ1 results (for image paths)")
    parser.add_argument("--out-dir", default="runs/rq1_hybrid")
    parser.add_argument("--prompts-file", default="data/prompts/experiment_prompts.json")
    parser.add_argument("--n-prompts", type=int, default=30)
    args = parser.parse_args()

    # Load generative results to get image paths
    with open(args.gen_results) as f:
        gen_data = json.load(f)

    # Build image lookup: (prompt_id, seed, condition) → image_path
    image_lookup = {}
    for r in gen_data["results"]:
        if "error" not in r and r.get("image_path"):
            key = (r["prompt_id"], r["seed"], r["condition"])
            image_lookup[key] = r["image_path"]

    # Load prompts
    with open(args.prompts_file) as f:
        prompts = json.load(f)["prompts"][:args.n_prompts]

    seed = 42  # Same seed as gen run
    conditions = ["baseline", "wrong_image", "wrong_audio"]
    total = len(prompts) * len(conditions)

    print("=" * 90)
    print("RQ1 HYBRID: SDXL-GENERATED IMAGES + CLAP-RETRIEVED AUDIO")
    print("=" * 90)
    print(f"  Prompts:     {len(prompts)}")
    print(f"  Seed:        {seed}")
    print(f"  Conditions:  {conditions}")
    print(f"  Total runs:  {total}")
    print(f"  Images from: {args.gen_results}")
    print("=" * 90)

    out_path = Path(args.out_dir)
    out_path.mkdir(parents=True, exist_ok=True)

    # Import what we need
    from src.generators.audio.retrieval import retrieve_audio_with_metadata
    from src.coherence.coherence_engine import evaluate_coherence
    from src.pipeline.generate_and_evaluate import (
        _collect_all_audio_paths,
        _select_mismatched_path,
        _infer_domain_from_path,
    )

    results = []
    t_start = time.time()

    for i_prompt, prompt_info in enumerate(prompts):
        pid = prompt_info["id"]
        text = prompt_info["text"]
        domain = prompt_info["domain"]

        for i_cond, condition in enumerate(conditions):
            idx = i_prompt * len(conditions) + i_cond + 1
            t0 = time.time()

            # Get the SDXL image for this task
            image_path = image_lookup.get((pid, seed, condition))
            if not image_path or not Path(image_path).exists():
                # Fallback: use baseline image for this prompt
                image_path = image_lookup.get((pid, seed, "baseline"))

            if not image_path or not Path(image_path).exists():
                print(f"  [{idx}/{total}] {pid} cond={condition}  SKIPPED (no image)")
                results.append({
                    "prompt_id": pid, "prompt_text": text, "domain": domain,
                    "seed": seed, "condition": condition, "error": "no image found",
                })
                continue

            # Retrieve audio via CLAP
            audio_result = retrieve_audio_with_metadata(prompt=text, min_similarity=0.10)
            audio_path = audio_result.audio_path
            audio_sim = audio_result.similarity

            # Apply perturbation for wrong_audio
            perturbation = {"applied": condition}
            if condition == "wrong_audio":
                orig_domain = _infer_domain_from_path(audio_path)
                audios = _collect_all_audio_paths()
                repl = _select_mismatched_path(audios, str(audio_path), orig_domain, seed)
                if repl:
                    perturbation["original_audio"] = str(audio_path)
                    perturbation["replacement_audio"] = repl
                    audio_path = repl

            # Evaluate coherence
            try:
                eval_out = evaluate_coherence(
                    text=text,
                    image_path=str(image_path),
                    audio_path=str(audio_path),
                )
                scores = eval_out.get("scores", {})
                elapsed = time.time() - t0
                msci_str = f"MSCI={scores.get('msci', 0):.4f}" if scores.get('msci') is not None else "MSCI=N/A"
                print(f"  [{idx}/{total}] {pid} cond={condition}  {msci_str}  ({elapsed:.1f}s)")

                results.append({
                    "prompt_id": pid,
                    "prompt_text": text,
                    "domain": domain,
                    "seed": seed,
                    "condition": condition,
                    "msci": scores.get("msci"),
                    "st_i": scores.get("st_i"),
                    "st_a": scores.get("st_a"),
                    "si_a": scores.get("si_a"),
                    "image_path": str(image_path),
                    "audio_path": str(audio_path),
                    "audio_sim": audio_sim,
                    "image_backend": "sdxl",
                    "audio_backend": "retrieval",
                    "perturbation": perturbation,
                })
            except Exception as e:
                elapsed = time.time() - t0
                print(f"  [{idx}/{total}] {pid} cond={condition}  ERROR: {str(e)[:60]}  ({elapsed:.1f}s)")
                results.append({
                    "prompt_id": pid, "prompt_text": text, "domain": domain,
                    "seed": seed, "condition": condition, "error": str(e),
                })

    total_time = time.time() - t_start

    # Save results
    results_path = out_path / "rq1_hybrid_results.json"
    with results_path.open("w") as f:
        json.dump({
            "experiment": "RQ1: MSCI Sensitivity (HYBRID: SDXL images + CLAP retrieval audio)",
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "config": {
                "mode": "hybrid",
                "image_backend": "sdxl (from generative run)",
                "audio_backend": "clap_retrieval",
                "n_prompts": len(prompts),
                "seeds": [seed],
                "conditions": conditions,
                "total_runs": total,
                "total_time_sec": round(total_time, 1),
            },
            "results": results,
        }, f, indent=2, default=str)

    print(f"\nResults saved: {results_path}")
    print(f"Total time: {total_time:.0f}s ({total_time/60:.1f}min)")

    # Quick summary
    print("\n" + "=" * 90)
    print("QUICK SUMMARY")
    print("=" * 90)

    for condition in conditions:
        scores = [r["msci"] for r in results if r.get("msci") is not None and r["condition"] == condition]
        if scores:
            print(f"  {condition:<14}  N={len(scores):>3}  mean={np.mean(scores):.4f}  std={np.std(scores):.4f}  median={np.median(scores):.4f}")

    baseline_scores = {}
    for r in results:
        if r["condition"] == "baseline" and r.get("msci") is not None:
            baseline_scores[r["prompt_id"]] = r["msci"]

    for condition in ["wrong_image", "wrong_audio"]:
        deltas = []
        for r in results:
            if r["condition"] == condition and r.get("msci") is not None:
                if r["prompt_id"] in baseline_scores:
                    deltas.append(baseline_scores[r["prompt_id"]] - r["msci"])
        if deltas:
            print(f"\n  Δ(baseline - {condition}):  mean={np.mean(deltas):+.4f}  std={np.std(deltas):.4f}  all_positive={all(d > 0 for d in deltas)}")

    print(f"\nRun: python scripts/analyze_results.py {results_path}")
    return 0


if __name__ == "__main__":
    sys.exit(main())
